# -*- coding: utf-8 -*-
"""Project 12. Parkinson's Disease Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lxBW1TzwK9o9n6fgzG7u9uAuJtdHPTXn

Importing the Dependencies
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score

"""Data Collection and Analysis"""

# loading the csv file in pandas dataframe
park_data = pd.read_csv('/content/parkinsons.csv')

# printing the first five rows of the data
park_data.head()

# number of rows and columns in the dataframe
park_data.shape

# getting some information about the data
park_data.info()

# checking the mising values in each column
park_data.isnull().sum()

# getting some statistical measures about the data
park_data.describe()

# ditribution of target variable
park_data['status'].value_counts()

"""1 --> Parkinson's Positive

0 --> Healthy
"""

# Selecting only the numeric columns
numeric_columns = park_data.select_dtypes(include=['int64', 'float64'])

# Grouping the data based on the 'status' column and calculating the mean
numeric_columns.groupby('status').mean()

"""Data Pre-Processing

Seperating the features and Target
"""

X = park_data.drop(columns=['name','status'], axis=1)
Y = park_data['status']

print(X)

print(Y)

"""Splitting the data to Training data and Test data"""

X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size=0.2, random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""Data Standardization"""

scaler = StandardScaler()

scaler.fit(X_train)

X_train = scaler.transform(X_train)

X_test = scaler.transform(X_test)

print(X_train)

"""Model Training

Support Vector Machine Model
"""

model = svm.SVC(kernel='linear')

# training the SVM model with training data
model.fit(X_train, Y_train)

"""Model Evaluation

Accuracy Score
"""

# accuracy score on training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)

print('Accuracy score of training data =', training_data_accuracy)

# accuracy score on test data
X_test_prediction = model.predict(X_test)
test_data_accuracy = accuracy_score(Y_test, X_test_prediction)

print('Accuracy score of test data =', test_data_accuracy)

"""Bulding a predictive system"""

input_data = (198.38300,215.20300,193.10400,0.00212,0.00001,0.00113,0.00135,0.00339,0.01263,0.11100,0.00640,0.00825,0.00951,0.01919,0.00119,30.77500,0.465946,0.738703,-7.067931,0.175181,1.512275,0.096320)

# changing input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

# standardize the data
std_data = scaler.transform(input_data_reshaped)

prediction = model.predict(std_data)
print(prediction)


if (prediction[0]==0):
  print("The person does not have Parkinson's Disease")

else:
  print("The person has Parkinson's Disease")

